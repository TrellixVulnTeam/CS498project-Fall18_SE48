{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import parse_argument\n",
    "from DataUtils.mainHelp import *\n",
    "import Config.config as configurable\n",
    "from DataUtils.mainHelp import *\n",
    "from DataUtils.Alphabet import *\n",
    "from test import load_test_data\n",
    "from test import T_Inference\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config file sucessfully.\npretrained_embed : True\nzeros : False\navg : False\nuniform : False\nnnembed : True\npretrained_embed_file : ./Data/embed/glove.sentiment.conj.pretrained.txt\ntrain_file : ./Data/mr_five_level/raw.clean.train\ndev_file : ./Data/mr_five_level/raw.clean.dev\ntest_file : ./Data/mr_five_level/raw.clean.test\nmax_count : -1\nmin_freq : 1\nshuffle : True\nepochs_shuffle : True\nsave_pkl : True\npkl_directory : ./Save_pkl\npkl_data : pkl_data.pkl\npkl_alphabet : pkl_alphabet.pkl\npkl_iter : pkl_iter.pkl\npkl_embed : pkl_embed.pkl\nsave_dict : True\nword_dict : dictionary_word.txt\nlabel_dict : dictionary_label.txt\nsave_direction : ./Save_model2\nsave_best_model_dir : ./Save_BModel2\nsave_model : True\nsave_all_model : False\nsave_best_model : True\nrm_model : True\nwide_conv : True\nlstm_layers : 1\nembed_dim : 300\nembed_finetune : True\nlstm_hiddens : 150\ndropout_emb : 0.5\ndropout : 0.5\nconv_filter_sizes : 1,2,3,4\nconv_filter_nums : 200\nadam : True\nsgd : False\nlearning_rate : 0.001\nweight_decay : 1.0e-8\nmomentum : 0.0\nclip_max_norm_use : True\nclip_max_norm : 10\nuse_lr_decay : False\nlr_rate_decay : 0.05\nmin_lrate : 0.000005\nmax_patience : 1\nnum_threads : 1\nuse_cuda : False\nepochs : 50\nearly_max_patience : 5\nbackward_batch_size : 1\nbatch_size : 16\ndev_batch_size : 16\ntest_batch_size : 16\nlog_interval : 100\n***************************************\nData Process : True\nTrain model : False\nTest model : False\ndemo model : True\nt_model : ./Save_BModel_C-BiLSTM-Attention/cnn_bilstm_attention_model_sst.pt\nt_data : test\npredict : False\n***************************************\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "config = parse_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data for process or pkl data.\nprocess demo sentence\nProcessing Data......\nLoading Data......\nData Path ['./Data/sst_binary/stsa.binary.trai', './Data/sst_binary/stsa.binary.dev', './Data/demo_sentence.txt']\nLoading Data Form ./Data/sst_binary/stsa.binary.trai\n\rreading the 200 line\t\rreading the 400 line\t\rreading the 600 line\t\rreading the 800 line\t\rreading the 1000 line\t\rreading the 1200 line\t\rreading the 1400 line\t\rreading the 1600 line\t\rreading the 1800 line\t\rreading the 2000 line\t\rreading the 2200 line\t\rreading the 2400 line\t\rreading the 2600 line\t\rreading the 2800 line\t\rreading the 3000 line\t\rreading the 3200 line\t\rreading the 3400 line\t\rreading the 3600 line\t\rreading the 3800 line\t\rreading the 4000 line\t\rreading the 4200 line\t\rreading the 4400 line\t\rreading the 4600 line\t\rreading the 4800 line\t\rreading the 5000 line\t\rreading the 5200 line\t\rreading the 5400 line\t\rreading the 5600 line\t\rreading the 5800 line\t\rreading the 6000 line\t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rreading the 6200 line\t\rreading the 6400 line\t\rreading the 6600 line\t\rreading the 6800 line\tshuffle train data......\nLoading Data Form ./Data/sst_binary/stsa.binary.dev\n\rreading the 200 line\t\rreading the 400 line\t\rreading the 600 line\t\rreading the 800 line\tLoading Data Form ./Data/demo_sentence.txt\ntrain sentence 6920, dev sentence 872, test sentence 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Vocab Start...... \nthe length of train data 6920\nthe length of data that create Alphabet 6920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************    create 1 iterator    **************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The all data has created iterator.\n*****************    create 2 iterator    **************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The all data has created iterator.\n*****************    create 3 iterator    **************\nThe all data has created iterator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/24049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 15%|█▍        | 3489/24049 [00:00<00:00, 34687.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 26%|██▌       | 6287/24049 [00:00<00:00, 32306.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 39%|███▉      | 9482/24049 [00:00<00:00, 32196.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 54%|█████▍    | 12958/24049 [00:00<00:00, 32922.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 64%|██████▍   | 15438/24049 [00:00<00:00, 29585.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 79%|███████▊  | 18883/24049 [00:00<00:00, 30892.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 93%|█████████▎| 22377/24049 [00:00<00:00, 32004.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 24049/24049 [00:00<00:00, 30540.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre_train embedding by nn.Embedding for out of vocabulary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count 13838, Embed dim 300.\nExact count 13129 / 13838\nFuzzy count 0 / 13838\n  INV count 13129 / 13838\n  OOV count 709 / 13838\n  OOV radio ===> 5.4%\n****************************************\nAll Data/Alphabet/Iterator Use Time 5.5344\n****************************************\nlearning algorithm is Adam.\nembed_num : 13838, class_num : 2\nPaddingID 1\nword_dict_path : ./Save_dictionary_cnn_bilstm_att/dictionary_word.txt\nlabel_dict_path : ./Save_dictionary_cnn_bilstm_att/dictionary_label.txt\nSaving dictionary\nSave dictionary finished.\nSaving dictionary\nSave dictionary finished.\n"
     ]
    }
   ],
   "source": [
    "#convert the above sentence to data \n",
    "sentence = \"The movie is good!\"\n",
    "train_iter, dev_iter, test_iter, alphabet = load_data(config=config, sentence=sentence)\n",
    "get_params(config=config, alphabet=alphabet)\n",
    "save_dictionary(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n[Conv2d(1, 200, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0)), Conv2d(1, 200, kernel_size=(4, 300), stride=(1, 1), padding=(2, 0)), Conv2d(1, 200, kernel_size=(5, 300), stride=(1, 1), padding=(2, 0))]\nload user model from ./Save_BModel_C-BiLSTM-Attention/cnn_bilstm_attention_model_sst.pt\nText_Classification(\n  (model): CNN_BiLSTM_Attention(\n    (embed): Embedding(13838, 300, padding_idx=1)\n    (bilstm): LSTM(300, 300, dropout=0.5, bidirectional=True)\n    (attn): Linear(in_features=300, out_features=1, bias=True)\n    (hidden2label1): Linear(in_features=900, out_features=450, bias=True)\n    (hidden2label2): Linear(in_features=450, out_features=2, bias=True)\n    (dropout): Dropout(p=0.5)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "#fit the sentence into model\n",
    "model = load_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data for model test.\nInitialize T_Inference\nThe movie is not good! is: 0 (0 is negative, 1 is positive)\nFinished Test.\n"
     ]
    }
   ],
   "source": [
    "data, path_source, path_result = load_test_data(train_iter, dev_iter, test_iter, config)\n",
    "infer = T_Inference(model=model, data=data, path_source = path_source, path_result= path_result,\n",
    "                     alphabet=alphabet, use_crf=config.use_crf, config=config)\n",
    "infer.oneSentenceInf(sentence)\n",
    "print(\"Finished Test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
