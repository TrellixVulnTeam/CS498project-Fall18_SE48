{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import parse_argument\n",
    "from DataUtils.mainHelp import *\n",
    "import Config.config as configurable\n",
    "from DataUtils.mainHelp import *\n",
    "from DataUtils.Alphabet import *\n",
    "from test import load_test_data\n",
    "from test import T_Inference\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config file sucessfully.\n",
      "pretrained_embed : True\n",
      "zeros : False\n",
      "avg : False\n",
      "uniform : False\n",
      "nnembed : True\n",
      "pretrained_embed_file : ./Data/embed/glove.sentiment.conj.pretrained.txt\n",
      "train_file : ./Data/mr_five_level/raw.clean.train\n",
      "dev_file : ./Data/mr_five_level/raw.clean.dev\n",
      "test_file : ./Data/mr_five_level/raw.clean.test\n",
      "max_count : -1\n",
      "min_freq : 1\n",
      "shuffle : True\n",
      "epochs_shuffle : True\n",
      "save_pkl : True\n",
      "pkl_directory : ./Save_pkl\n",
      "pkl_data : pkl_data.pkl\n",
      "pkl_alphabet : pkl_alphabet.pkl\n",
      "pkl_iter : pkl_iter.pkl\n",
      "pkl_embed : pkl_embed.pkl\n",
      "save_dict : True\n",
      "word_dict : dictionary_word.txt\n",
      "label_dict : dictionary_label.txt\n",
      "save_direction : ./Save_model2\n",
      "save_best_model_dir : ./Save_BModel2\n",
      "save_model : True\n",
      "save_all_model : False\n",
      "save_best_model : True\n",
      "rm_model : True\n",
      "wide_conv : True\n",
      "lstm_layers : 1\n",
      "embed_dim : 300\n",
      "embed_finetune : True\n",
      "lstm_hiddens : 150\n",
      "dropout_emb : 0.5\n",
      "dropout : 0.5\n",
      "conv_filter_sizes : 1,2,3,4\n",
      "conv_filter_nums : 200\n",
      "adam : True\n",
      "sgd : False\n",
      "learning_rate : 0.001\n",
      "weight_decay : 1.0e-8\n",
      "momentum : 0.0\n",
      "clip_max_norm_use : True\n",
      "clip_max_norm : 10\n",
      "use_lr_decay : False\n",
      "lr_rate_decay : 0.05\n",
      "min_lrate : 0.000005\n",
      "max_patience : 1\n",
      "num_threads : 1\n",
      "use_cuda : False\n",
      "epochs : 50\n",
      "early_max_patience : 5\n",
      "backward_batch_size : 1\n",
      "batch_size : 50\n",
      "dev_batch_size : 16\n",
      "test_batch_size : 16\n",
      "log_interval : 100\n",
      "***************************************\n",
      "Data Process : True\n",
      "Train model : True\n",
      "Test model : False\n",
      "demo model : False\n",
      "t_model : ./Save_BModel_CNN/cnn_model_sst.pt\n",
      "t_data : test\n",
      "predict : False\n",
      "***************************************\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "config = parse_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data for process or pkl data.\n",
      "process data\n",
      "Processing Data......\n",
      "Loading Data......\n",
      "Data Path ['./Data/sst_binary/stsa.binary.trai', './Data/sst_binary/stsa.binary.dev', './Data/sst_binary/stsa.binary.test']\n",
      "Loading Data Form ./Data/sst_binary/stsa.binary.trai\n",
      "reading the 6800 line\tshuffle train data......\n",
      "Loading Data Form ./Data/sst_binary/stsa.binary.dev\n",
      "reading the 800 line\tLoading Data Form ./Data/sst_binary/stsa.binary.test\n",
      "reading the 1800 line\ttrain sentence 6920, dev sentence 872, test sentence 1821.\n",
      "Build Vocab Start...... \n",
      "the length of train data 6920\n",
      "the length of data that create Alphabet 6920\n",
      "*****************    create 1 iterator    **************\n",
      "The all data has created iterator.\n",
      "*****************    create 2 iterator    **************\n",
      "The all data has created iterator.\n",
      "*****************    create 3 iterator    **************\n",
      "The all data has created iterator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24049/24049 [00:00<00:00, 28578.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre_train embedding by nn.Embedding for out of vocabulary.\n",
      "Words count 13838, Embed dim 300.\n",
      "Exact count 13129 / 13838\n",
      "Fuzzy count 0 / 13838\n",
      "  INV count 13129 / 13838\n",
      "  OOV count 709 / 13838\n",
      "  OOV radio ===> 5.4%\n",
      "****************************************\n",
      "All Data/Alphabet/Iterator Use Time 6.0524\n",
      "****************************************\n",
      "learning algorithm is Adam.\n",
      "embed_num : 13838, class_num : 2\n",
      "PaddingID 1\n",
      "word_dict_path : ./Save_dictionary_cnn/dictionary_word.txt\n",
      "label_dict_path : ./Save_dictionary_cnn/dictionary_label.txt\n",
      "Saving dictionary\n",
      "Save dictionary finished.\n",
      "Saving dictionary\n",
      "Save dictionary finished.\n"
     ]
    }
   ],
   "source": [
    "#convert the above sentence to data \n",
    "sentence = \"The moive is not good!\"\n",
    "train_iter, dev_iter, test_iter, alphabet = load_data(config=config, sentence=sentence)\n",
    "get_params(config=config, alphabet=alphabet)\n",
    "save_dictionary(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************\n",
      "Using Wide Convolution\n",
      "Text_Classification(\n",
      "  (model): CNN(\n",
      "    (embed): Embedding(13838, 300, padding_idx=1)\n",
      "    (dropout_embed): Dropout(p=0.5)\n",
      "    (dropout): Dropout(p=0.5)\n",
      "    (linear): Linear(in_features=800, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#fit the sentence into model\n",
    "model = load_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data for model test.\n",
      "Initialize T_Inference\n",
      "The moive is not good! is: 9 (0 is negative, 1 is positive)\n",
      "Finished Test.\n"
     ]
    }
   ],
   "source": [
    "data, path_source, path_result = load_test_data(train_iter, dev_iter, test_iter, config)\n",
    "infer = T_Inference(model=model, data=data, path_source = path_source, path_result= path_result,\n",
    "                     alphabet=alphabet, use_crf=config.use_crf, config=config)\n",
    "infer.oneSentenceInf(sentence)\n",
    "print(\"Finished Test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
